import { useCallback, useRef, useState } from "react";

import type {
  RecordingState,
  AudioProcessingResult,
  AudioError,
} from "../utils/types";

export function useRecording(audioContext: AudioContext | null) {
  const [recordingState, setRecordingState] = useState<RecordingState>({
    isRecording: false,
    isPlaying: false,
    audioBuffer: null,
    recordingTime: 0,
    maxRecordingTime: 2.0, // 2ÁßíÈñì„ÅÆÈå≤Èü≥
  });

  const mediaStreamRef = useRef<MediaStream | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordingDataRef = useRef<Blob[]>([]);
  const recordingTimerRef = useRef<number | null>(null);

  // „Éû„Ç§„ÇØ„Å∏„ÅÆ„Ç¢„ÇØ„Çª„ÇπË®±ÂèØ„ÇíÂèñÂæó
  const requestMicrophoneAccess = async (): Promise<
    AudioProcessingResult<MediaStream>
  > => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
          sampleRate: 44100,
        },
      });

      mediaStreamRef.current = stream;

      return {
        success: true,
        data: stream,
      };
    } catch (error) {
      const audioError: AudioError = {
        code: "MICROPHONE_ACCESS_ERROR",
        message:
          error instanceof Error ? error.message : "Microphone access denied",
        details: { error },
      };

      return {
        success: false,
        error: audioError,
      };
    }
  };

  // Èå≤Èü≥ÈñãÂßã
  const startRecording = useCallback(async (): Promise<
    AudioProcessingResult<void>
  > => {
    try {
      if (!audioContext) {
        throw new Error("Audio context not initialized");
      }

      if (recordingState.isRecording) {
        return {
          success: false,
          error: {
            code: "RECORDING_ALREADY_IN_PROGRESS",
            message: "Recording is already in progress",
          },
        };
      }

      // „Éû„Ç§„ÇØ„Ç¢„ÇØ„Çª„Çπ
      const micResult = await requestMicrophoneAccess();
      if (!micResult.success || !micResult.data) {
        return {
          success: false,
          error: micResult.error,
        };
      }

      const stream = micResult.data;

      // MediaRecorder„ÅÆË®≠ÂÆö
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: "audio/webm;codecs=opus",
      });

      recordingDataRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          recordingDataRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const blob = new Blob(recordingDataRef.current, { type: "audio/webm" });
        const arrayBuffer = await blob.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        console.log(`üìä Èå≤Èü≥„Éá„Éº„Çø:`, {
          blobSize: blob.size,
          audioBufferDuration: audioBuffer.duration,
          audioBufferLength: audioBuffer.length,
          sampleRate: audioBuffer.sampleRate,
          expectedDuration: recordingState.maxRecordingTime,
        });

        setRecordingState((prev) => ({
          ...prev,
          isRecording: false,
          audioBuffer,
          recordingTime: 0,
        }));

        // „Çπ„Éà„É™„Éº„É†„ÇíÂÅúÊ≠¢
        if (mediaStreamRef.current) {
          mediaStreamRef.current.getTracks().forEach((track) => track.stop());
          mediaStreamRef.current = null;
        }
      };

      mediaRecorderRef.current = mediaRecorder;

      // Èå≤Èü≥ÈñãÂßã
      mediaRecorder.start();

      // Èå≤Èü≥ÊôÇÈñì„ÅÆÊõ¥Êñ∞
      const startTime = Date.now();
      const maxTime = recordingState.maxRecordingTime;

      recordingTimerRef.current = window.setInterval(() => {
        const elapsed = (Date.now() - startTime) / 1000;
        const recordingTime = Math.min(elapsed, maxTime);

        setRecordingState((prev) => ({
          ...prev,
          recordingTime,
        }));

        // ÊúÄÂ§ßÈå≤Èü≥ÊôÇÈñì„Å´ÈÅî„Åó„Åü„ÇâÂÅúÊ≠¢
        if (elapsed >= maxTime) {
          // „Çø„Ç§„Éû„Éº„Çí„ÇØ„É™„Ç¢
          if (recordingTimerRef.current) {
            clearInterval(recordingTimerRef.current);
            recordingTimerRef.current = null;
          }

          // Áõ¥Êé•MediaRecorder„ÇíÂÅúÊ≠¢
          if (
            mediaRecorderRef.current &&
            mediaRecorderRef.current.state !== "inactive"
          ) {
            mediaRecorderRef.current.stop();
          }
        }
      }, 50); // 50ms„Å´Â§âÊõ¥„Åó„Å¶„Çà„ÇäÊªë„Çâ„Åã„Å´

      setRecordingState((prev) => ({
        ...prev,
        isRecording: true,
        recordingTime: 0,
      }));

      return {
        success: true,
      };
    } catch (error) {
      const audioError: AudioError = {
        code: "RECORDING_START_ERROR",
        message:
          error instanceof Error ? error.message : "Failed to start recording",
        details: { error },
      };

      return {
        success: false,
        error: audioError,
      };
    }
  }, [
    audioContext,
    recordingState.isRecording,
    recordingState.maxRecordingTime,
  ]);

  // Èå≤Èü≥ÂÅúÊ≠¢
  const stopRecording = useCallback((): Promise<
    AudioProcessingResult<void>
  > => {
    try {
      if (!recordingState.isRecording) {
        return Promise.resolve({
          success: false,
          error: {
            code: "RECORDING_NOT_IN_PROGRESS",
            message: "Recording is not in progress",
          },
        });
      }

      // „Çø„Ç§„Éû„Éº„Çí„ÇØ„É™„Ç¢
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
        recordingTimerRef.current = null;
      }

      // MediaRecorder„ÇíÂÅúÊ≠¢
      if (
        mediaRecorderRef.current &&
        mediaRecorderRef.current.state !== "inactive"
      ) {
        mediaRecorderRef.current.stop();
      }

      return Promise.resolve({
        success: true,
      });
    } catch (error) {
      const audioError: AudioError = {
        code: "RECORDING_STOP_ERROR",
        message:
          error instanceof Error ? error.message : "Failed to stop recording",
        details: { error },
      };

      return Promise.resolve({
        success: false,
        error: audioError,
      });
    }
  }, [recordingState.isRecording]);

  // „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
  const cleanup = useCallback(() => {
    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
      recordingTimerRef.current = null;
    }

    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((track) => track.stop());
      mediaStreamRef.current = null;
    }

    if (
      mediaRecorderRef.current &&
      mediaRecorderRef.current.state !== "inactive"
    ) {
      mediaRecorderRef.current.stop();
    }
  }, []);

  return {
    ...recordingState,
    startRecording,
    stopRecording,
    cleanup,
  };
}
