import { useCallback, useRef } from "react";

import { useWorkletActions, useWorkletState } from "../store/audioStore";

import type {
  AudioError,
  AudioProcessingResult,
  ChunkData,
  WorkletMessage,
  WorkletMessagePayload,
} from "../utils/types";

export function useAudioWorkletZustand(audioContext: AudioContext | null) {
  const workletState = useWorkletState();
  const {
    setWorkletInitialized,
    setWorkletRecording,
    addChunk,
    clearChunks,
    setWorkletFrames,
    setWorkletTotalChunks,
  } = useWorkletActions();

  const workletNodeRef = useRef<AudioWorkletNode | null>(null);
  const sourceNodeRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);

  // AudioWorklet„Åã„Çâ„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏Âá¶ÁêÜ
  const handleWorkletMessage = useCallback(
    (message: WorkletMessage) => {
      switch (message.type) {
        case "recording-started":
          console.log("üì° Recording started:", message.payload);
          break;

        case "chunk": {
          const payload = message.payload as WorkletMessagePayload<"chunk">;
          if (!audioContext) return;

          const chunkData: ChunkData = {
            id: payload.chunkIndex,
            startTime: payload.timestamp,
            endTime:
              payload.timestamp +
              payload.audioData.length / audioContext.sampleRate,
            data: payload.audioData,
            isSelected: false,
          };

          addChunk(chunkData);
          console.log(`üîÑ Chunk added to store: ${payload.chunkIndex}`);

          console.log(`üì¶ Chunk ${payload.chunkIndex} received:`, {
            size: payload.audioData.length,
            min: payload.minValue,
            max: payload.maxValue,
          });
          break;
        }

        case "recording-stopped": {
          const payload =
            message.payload as WorkletMessagePayload<"recording-stopped">;
          console.log("üì° Recording stopped:", payload);
          setWorkletFrames(payload.totalFrames);
          break;
        }

        default:
          console.warn("Unknown worklet message:", message.type);
      }
    },
    [audioContext, addChunk, setWorkletFrames],
  );

  // AudioWorkletProcessor„ÇíÂàùÊúüÂåñ
  const initializeWorklet = useCallback(async (): Promise<
    AudioProcessingResult<void>
  > => {
    try {
      if (!audioContext) {
        throw new Error("Audio context not initialized");
      }

      // AudioWorkletProcessor„ÇíË™≠„ÅøËæº„Åø
      const workletPath = new URL(
        "../worklets/recording-processor.js",
        import.meta.url,
      );
      await audioContext.audioWorklet.addModule(workletPath);

      setWorkletInitialized(true);
      console.log("‚úÖ AudioWorkletProcessor loaded successfully");

      return { success: true };
    } catch (error) {
      const audioError: AudioError = {
        code: "WORKLET_INITIALIZATION_ERROR",
        message:
          error instanceof Error
            ? error.message
            : "Failed to initialize AudioWorklet",
        details: { error },
      };

      return { success: false, error: audioError };
    }
  }, [audioContext, setWorkletInitialized]);

  // Èå≤Èü≥ÈñãÂßãÔºàAudioWorklet„Çí‰ΩøÁî®Ôºâ
  const startWorkletRecording = useCallback(
    async (duration: number = 2.0): Promise<AudioProcessingResult<void>> => {
      try {
        if (!audioContext) {
          throw new Error("Audio context not initialized");
        }

        if (workletState.isRecording) {
          return {
            success: false,
            error: {
              code: "RECORDING_ALREADY_IN_PROGRESS",
              message: "Recording is already in progress",
            },
          };
        }

        // „Éû„Ç§„ÇØ„Ç¢„ÇØ„Çª„Çπ„ÇíÂèñÂæó
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: false,
            noiseSuppression: false,
            autoGainControl: false,
            sampleRate: audioContext.sampleRate,
          },
        });

        // AudioWorkletNode‰ΩúÊàê
        const workletNode = new AudioWorkletNode(
          audioContext,
          "recording-processor",
          {
            numberOfInputs: 1,
            numberOfOutputs: 1,
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "speakers",
          },
        );

        // MediaStreamAudioSourceNode‰ΩúÊàê
        const sourceNode = audioContext.createMediaStreamSource(stream);

        // „É°„ÉÉ„Çª„Éº„Ç∏„Éè„É≥„Éâ„É©„ÉºË®≠ÂÆö
        workletNode.port.onmessage = (event: MessageEvent<WorkletMessage>) => {
          handleWorkletMessage(event.data);
        };

        // „Éé„Éº„ÉâÊé•Á∂ö
        sourceNode.connect(workletNode);

        // ÂèÇÁÖß„Çí‰øùÂ≠ò
        workletNodeRef.current = workletNode;
        sourceNodeRef.current = sourceNode;
        mediaStreamRef.current = stream;

        // Èå≤Èü≥ÈñãÂßã
        workletNode.port.postMessage({
          type: "start",
          payload: { duration },
        });

        // Áä∂ÊÖã„ÇíÊõ¥Êñ∞
        setWorkletRecording(true);
        clearChunks();
        setWorkletTotalChunks(150);
        setWorkletFrames(0);

        console.log("üé§ AudioWorklet recording started:", { duration });

        return { success: true };
      } catch (error) {
        const audioError: AudioError = {
          code: "WORKLET_RECORDING_START_ERROR",
          message:
            error instanceof Error
              ? error.message
              : "Failed to start worklet recording",
          details: { error },
        };

        return { success: false, error: audioError };
      }
    },
    [
      audioContext,
      workletState.isRecording,
      setWorkletRecording,
      clearChunks,
      setWorkletTotalChunks,
      setWorkletFrames,
      handleWorkletMessage,
    ],
  );

  // Èå≤Èü≥ÂÅúÊ≠¢
  const stopWorkletRecording = useCallback((): AudioProcessingResult<void> => {
    try {
      if (!workletState.isRecording) {
        return {
          success: false,
          error: {
            code: "RECORDING_NOT_IN_PROGRESS",
            message: "Recording is not in progress",
          },
        };
      }

      // Èå≤Èü≥ÂÅúÊ≠¢
      if (workletNodeRef.current) {
        workletNodeRef.current.port.postMessage({ type: "stop" });
      }

      // „Éé„Éº„ÉâÂàáÊñ≠
      if (sourceNodeRef.current) {
        sourceNodeRef.current.disconnect();
      }

      if (workletNodeRef.current) {
        workletNodeRef.current.disconnect();
      }

      // MediaStream„ÇíÂÅúÊ≠¢
      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach((track) => track.stop());
      }

      // ÂèÇÁÖß„Çí„ÇØ„É™„Ç¢
      workletNodeRef.current = null;
      sourceNodeRef.current = null;
      mediaStreamRef.current = null;

      setWorkletRecording(false);

      console.log("üõë AudioWorklet recording stopped");

      return { success: true };
    } catch (error) {
      const audioError: AudioError = {
        code: "WORKLET_RECORDING_STOP_ERROR",
        message:
          error instanceof Error
            ? error.message
            : "Failed to stop worklet recording",
        details: { error },
      };

      return { success: false, error: audioError };
    }
  }, [workletState.isRecording, setWorkletRecording]);

  // „ÉÅ„É£„É≥„ÇØ„Åã„ÇâAudioBuffer„Çí‰ΩúÊàê
  const createAudioBufferFromChunks = useCallback((): AudioBuffer | null => {
    if (!audioContext || workletState.chunks.length === 0) {
      return null;
    }

    try {
      // ÂÖ®„ÉÅ„É£„É≥„ÇØ„ÅÆ„Çµ„É≥„Éó„É´Êï∞„ÇíË®àÁÆó
      const totalSamples = workletState.chunks.reduce(
        (sum, chunk) => sum + chunk.data.length,
        0,
      );

      // AudioBuffer„Çí‰ΩúÊàê
      const audioBuffer = audioContext.createBuffer(
        1, // „É¢„Éé„É©„É´
        totalSamples,
        audioContext.sampleRate,
      );

      // „ÉÅ„É£„É≥„ÇØ„Éá„Éº„Çø„ÇíÁµêÂêà
      const channelData = audioBuffer.getChannelData(0);
      let offset = 0;

      for (const chunk of workletState.chunks) {
        channelData.set(chunk.data, offset);
        offset += chunk.data.length;
      }

      console.log("üîä AudioBuffer created from chunks:", {
        totalSamples,
        duration: audioBuffer.duration,
        chunkCount: workletState.chunks.length,
      });

      return audioBuffer;
    } catch (error) {
      console.error("‚ùå Failed to create AudioBuffer from chunks:", error);
      return null;
    }
  }, [audioContext, workletState.chunks]);

  // „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
  const cleanup = useCallback(() => {
    if (workletState.isRecording) {
      stopWorkletRecording();
    }
  }, [workletState.isRecording, stopWorkletRecording]);

  return {
    workletState,
    initializeWorklet,
    startWorkletRecording,
    stopWorkletRecording,
    createAudioBufferFromChunks,
    cleanup,
  };
}
